{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e75a82",
   "metadata": {
    "papermill": {
     "duration": 0.007011,
     "end_time": "2024-01-04T20:46:00.948724",
     "exception": false,
     "start_time": "2024-01-04T20:46:00.941713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 0: Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc87d654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:46:00.963701Z",
     "iopub.status.busy": "2024-01-04T20:46:00.962892Z",
     "iopub.status.idle": "2024-01-04T20:46:06.063480Z",
     "shell.execute_reply": "2024-01-04T20:46:06.062480Z"
    },
    "papermill": {
     "duration": 5.111143,
     "end_time": "2024-01-04T20:46:06.066403",
     "exception": false,
     "start_time": "2024-01-04T20:46:00.955260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8753eb85",
   "metadata": {
    "papermill": {
     "duration": 0.006757,
     "end_time": "2024-01-04T20:46:06.082655",
     "exception": false,
     "start_time": "2024-01-04T20:46:06.075898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 1: Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f36fc1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:46:06.099852Z",
     "iopub.status.busy": "2024-01-04T20:46:06.098728Z",
     "iopub.status.idle": "2024-01-04T20:46:21.002686Z",
     "shell.execute_reply": "2024-01-04T20:46:21.001837Z"
    },
    "papermill": {
     "duration": 14.914991,
     "end_time": "2024-01-04T20:46:21.004717",
     "exception": false,
     "start_time": "2024-01-04T20:46:06.089726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codeplay produces compilers, debuggers, runtimes, testing systems, and other specialized tools to aid software development for heterogeneous systems and special purpose processor architectures, including GPUs and DSPs.\n"
     ]
    }
   ],
   "source": [
    "data_path = '/kaggle/input/wikipedia-sentences/wikisent2.txt'\n",
    "\n",
    "sentence_count = 50000\n",
    "\n",
    "with open(data_path, 'r') as file:\n",
    "    file_text = file.read()\n",
    "file_lines = random.sample(file_text.split('\\n')[:-1], sentence_count)\n",
    "\n",
    "print(random.choice(file_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68bd0d0",
   "metadata": {
    "papermill": {
     "duration": 0.006263,
     "end_time": "2024-01-04T20:46:21.017781",
     "exception": false,
     "start_time": "2024-01-04T20:46:21.011518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 2: Prepare Tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e83f9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:46:21.032403Z",
     "iopub.status.busy": "2024-01-04T20:46:21.031655Z",
     "iopub.status.idle": "2024-01-04T20:46:54.807606Z",
     "shell.execute_reply": "2024-01-04T20:46:54.806737Z"
    },
    "papermill": {
     "duration": 33.786026,
     "end_time": "2024-01-04T20:46:54.810084",
     "exception": false,
     "start_time": "2024-01-04T20:46:21.024058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "Collecting en-core-web-sm==3.7.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.3.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.12)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.1.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'title', 'is', 'based', 'on', 'a', 'joke', 'circulating', 'on', 'the', 'Internet', 'with', 'a', 'punchline', 'of', 'Cheeses', 'of', 'Nazareth', '.']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "print(en_tokenizer(random.choice(file_lines)))\n",
    "\n",
    "def build_vocab(train_data, tokenizer):\n",
    "    words = Counter()\n",
    "    for sentence in train_data:\n",
    "        words.update(tokenizer(sentence))\n",
    "    return vocab(words, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "en_vocab = build_vocab(file_lines, en_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bfd5a5",
   "metadata": {
    "papermill": {
     "duration": 0.00771,
     "end_time": "2024-01-04T20:46:54.826214",
     "exception": false,
     "start_time": "2024-01-04T20:46:54.818504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 3: Process Data as Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a809c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:46:54.844121Z",
     "iopub.status.busy": "2024-01-04T20:46:54.843022Z",
     "iopub.status.idle": "2024-01-04T20:46:59.946418Z",
     "shell.execute_reply": "2024-01-04T20:46:59.945383Z"
    },
    "papermill": {
     "duration": 5.114775,
     "end_time": "2024-01-04T20:46:59.948832",
     "exception": false,
     "start_time": "2024-01-04T20:46:54.834057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   71,   394, 11755,     8, 63695, 63696,    28,  1154,  5822,  1657,\n",
      "          786,  2205,     8, 11307,     7,  3474,    83,  1027, 15673,    21])\n"
     ]
    }
   ],
   "source": [
    "def process_data(lines):\n",
    "    data = []\n",
    "    for sentence in lines:\n",
    "        en_tensor = torch.tensor([en_vocab[token] for token in en_tokenizer(sentence.rstrip(\"\\n\"))],\n",
    "                                  dtype=torch.long)\n",
    "        data.append(en_tensor)\n",
    "    return data\n",
    "\n",
    "train_data = process_data(file_lines)\n",
    "print(random.choice(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7ab63",
   "metadata": {
    "papermill": {
     "duration": 0.008327,
     "end_time": "2024-01-04T20:46:59.965945",
     "exception": false,
     "start_time": "2024-01-04T20:46:59.957618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 4: Create Dataset & DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5806281a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:46:59.983439Z",
     "iopub.status.busy": "2024-01-04T20:46:59.983050Z",
     "iopub.status.idle": "2024-01-04T20:46:59.993351Z",
     "shell.execute_reply": "2024-01-04T20:46:59.992629Z"
    },
    "papermill": {
     "duration": 0.021119,
     "end_time": "2024-01-04T20:46:59.995232",
     "exception": false,
     "start_time": "2024-01-04T20:46:59.974113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, train_data):\n",
    "        self.train_data = train_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.train_data[index]\n",
    "\n",
    "SEQUENCE_LENGTH = 150\n",
    "BATCH_SIZE = 16\n",
    "PAD_IDX = en_vocab['<pad>']\n",
    "BOS_IDX = en_vocab['<bos>']\n",
    "EOS_IDX = en_vocab['<eos>']\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    en_batch = []\n",
    "    label_batch = []\n",
    "    for en_item in data_batch:\n",
    "        sentence = torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0)\n",
    "        sentence = nn.ConstantPad1d((0, SEQUENCE_LENGTH - sentence.size(0)), PAD_IDX)(sentence)\n",
    "        current_labels = []\n",
    "        for idx in range(1, len(sentence)):\n",
    "            current_labels.append(sentence[idx])\n",
    "        current_labels.append(torch.tensor(PAD_IDX))\n",
    "            \n",
    "        en_batch.append(sentence)\n",
    "        label_batch.append(current_labels)\n",
    "    \n",
    "    en_batch = torch.stack(en_batch)\n",
    "    label_batch = torch.tensor(label_batch)\n",
    "    return (en_batch, label_batch)\n",
    "    \n",
    "train_dataset = TranslationDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c07a4",
   "metadata": {
    "papermill": {
     "duration": 0.007849,
     "end_time": "2024-01-04T20:47:00.010911",
     "exception": false,
     "start_time": "2024-01-04T20:47:00.003062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 5: Create Transformer Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2544589f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:47:00.028376Z",
     "iopub.status.busy": "2024-01-04T20:47:00.027842Z",
     "iopub.status.idle": "2024-01-04T20:47:00.052933Z",
     "shell.execute_reply": "2024-01-04T20:47:00.052090Z"
    },
    "papermill": {
     "duration": 0.036031,
     "end_time": "2024-01-04T20:47:00.054776",
     "exception": false,
     "start_time": "2024-01-04T20:47:00.018745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.query_layer = nn.Linear(d_model, d_model)\n",
    "        self.key_layer = nn.Linear(d_model, d_model)\n",
    "        self.value_layer = nn.Linear(d_model, d_model)\n",
    "        self.output_layer = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
    "        attention_probabilities = torch.softmax(attention_scores, dim=-1)\n",
    "        output = torch.matmul(attention_probabilities, V)\n",
    "        return output\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "    \n",
    "    def forward(self, Q, K, V, mask):\n",
    "        Q = self.split_heads(self.query_layer(Q))\n",
    "        K = self.split_heads(self.key_layer(K))\n",
    "        V = self.split_heads(self.value_layer(V))\n",
    "        \n",
    "        attention_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.output_layer(self.combine_heads(attention_output))\n",
    "        return output\n",
    "    \n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.positional_encoding = torch.zeros(max_seq_length, d_model, device=DEVICE)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float32, device=DEVICE).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, device=DEVICE).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        self.positional_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.positional_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('_positional_encoding', self.positional_encoding.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.positional_encoding[:, :x.size(2)]\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        self.self_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attention_output = self.self_attention(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attention_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "        \n",
    "        self.layers = nn.ModuleList([TransformerBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        \n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def generate_mask(self, src):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "    \n",
    "    def forward(self, src):\n",
    "        src_mask = self.generate_mask(src)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.embedding(src)))\n",
    "        \n",
    "        output = src_embedded\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_mask)\n",
    "        \n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae25690",
   "metadata": {
    "papermill": {
     "duration": 0.00826,
     "end_time": "2024-01-04T20:47:00.070976",
     "exception": false,
     "start_time": "2024-01-04T20:47:00.062716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 8: Training Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f5fa68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:47:00.087863Z",
     "iopub.status.busy": "2024-01-04T20:47:00.087564Z",
     "iopub.status.idle": "2024-01-04T20:47:03.422155Z",
     "shell.execute_reply": "2024-01-04T20:47:03.421119Z"
    },
    "papermill": {
     "duration": 3.346098,
     "end_time": "2024-01-04T20:47:03.424970",
     "exception": false,
     "start_time": "2024-01-04T20:47:00.078872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(en_vocab)\n",
    "d_model = 1024\n",
    "num_heads = 64\n",
    "num_layers = 24\n",
    "d_ff = 1024\n",
    "dropout = 0.1\n",
    "learning_rate = 0.00003\n",
    "\n",
    "transformer = Transformer(vocab_size, d_model, num_heads,\n",
    "                          num_layers, d_ff, SEQUENCE_LENGTH, dropout).to(DEVICE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3463a7",
   "metadata": {
    "papermill": {
     "duration": 0.008866,
     "end_time": "2024-01-04T20:47:03.445713",
     "exception": false,
     "start_time": "2024-01-04T20:47:03.436847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 9: Define Training Procedure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc1bd6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:47:03.463879Z",
     "iopub.status.busy": "2024-01-04T20:47:03.462998Z",
     "iopub.status.idle": "2024-01-04T20:47:03.471230Z",
     "shell.execute_reply": "2024-01-04T20:47:03.470352Z"
    },
    "papermill": {
     "duration": 0.019439,
     "end_time": "2024-01-04T20:47:03.473142",
     "exception": false,
     "start_time": "2024-01-04T20:47:03.453703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for idx, (src, labels) in enumerate(train_loader):           \n",
    "        src = src.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        logits = transformer(src)\n",
    "        \n",
    "        logits = logits.view(-1, logits.size(-1))\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "    return losses / len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef327a",
   "metadata": {
    "papermill": {
     "duration": 0.007946,
     "end_time": "2024-01-04T20:47:03.489046",
     "exception": false,
     "start_time": "2024-01-04T20:47:03.481100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 10: Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ee947e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:47:03.507187Z",
     "iopub.status.busy": "2024-01-04T20:47:03.506348Z",
     "iopub.status.idle": "2024-01-04T20:47:03.512676Z",
     "shell.execute_reply": "2024-01-04T20:47:03.511773Z"
    },
    "papermill": {
     "duration": 0.017571,
     "end_time": "2024-01-04T20:47:03.514594",
     "exception": false,
     "start_time": "2024-01-04T20:47:03.497023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(transformer, train_loader, optimizer)\n",
    "    end_time = time.time()\n",
    "    print((f'Epoch: {epoch}, Train loss: {train_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e9b13",
   "metadata": {
    "papermill": {
     "duration": 0.007885,
     "end_time": "2024-01-04T20:47:03.530405",
     "exception": false,
     "start_time": "2024-01-04T20:47:03.522520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 11: Save Model & Vocab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0546c74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:47:03.548125Z",
     "iopub.status.busy": "2024-01-04T20:47:03.547415Z",
     "iopub.status.idle": "2024-01-04T20:47:05.645657Z",
     "shell.execute_reply": "2024-01-04T20:47:05.644854Z"
    },
    "papermill": {
     "duration": 2.10983,
     "end_time": "2024-01-04T20:47:05.648183",
     "exception": false,
     "start_time": "2024-01-04T20:47:03.538353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model for inference\n",
    "torch.save(transformer.state_dict(), 'model.pth')\n",
    "\n",
    "import pickle\n",
    "with open('en_vocab.pkl', 'wb') as file:\n",
    "    pickle.dump(en_vocab, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a537c0d",
   "metadata": {
    "papermill": {
     "duration": 0.00804,
     "end_time": "2024-01-04T20:47:05.665361",
     "exception": false,
     "start_time": "2024-01-04T20:47:05.657321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 12: Load Model & Vocab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b3a4384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:47:05.682989Z",
     "iopub.status.busy": "2024-01-04T20:47:05.682399Z",
     "iopub.status.idle": "2024-01-04T20:47:09.955009Z",
     "shell.execute_reply": "2024-01-04T20:47:09.954161Z"
    },
    "papermill": {
     "duration": 4.28404,
     "end_time": "2024-01-04T20:47:09.957347",
     "exception": false,
     "start_time": "2024-01-04T20:47:05.673307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_vocab_path = '/kaggle/working/en_vocab.pkl'\n",
    "model_path = '/kaggle/working/model.pth'\n",
    "\n",
    "generator_transformer = Transformer(vocab_size, d_model, num_heads,\n",
    "                          num_layers, d_ff, SEQUENCE_LENGTH, dropout).to(DEVICE)\n",
    "\n",
    "generator_transformer.load_state_dict(torch.load(model_path))\n",
    "generator_transformer.eval()\n",
    "\n",
    "with open(en_vocab_path, 'rb') as file:\n",
    "    en_vocab = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910744b6",
   "metadata": {
    "papermill": {
     "duration": 0.008559,
     "end_time": "2024-01-04T20:47:09.974462",
     "exception": false,
     "start_time": "2024-01-04T20:47:09.965903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 13: Model Evaluation Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe6bf13d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:47:09.992666Z",
     "iopub.status.busy": "2024-01-04T20:47:09.991992Z",
     "iopub.status.idle": "2024-01-04T20:47:10.000705Z",
     "shell.execute_reply": "2024-01-04T20:47:09.999831Z"
    },
    "papermill": {
     "duration": 0.01961,
     "end_time": "2024-01-04T20:47:10.002499",
     "exception": false,
     "start_time": "2024-01-04T20:47:09.982889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(model, initial_input, max_length):\n",
    "    current_input = initial_input.view(1, -1).to(DEVICE)\n",
    "\n",
    "    generated_sequence = initial_input.tolist()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            padded_input = nn.ConstantPad1d((SEQUENCE_LENGTH - current_input.size(1), 0), PAD_IDX)(current_input)\n",
    "            logits = model(padded_input)\n",
    "            next_word = torch.argmax(logits[:, -1, :], dim=-1)\n",
    "            print(next_word)\n",
    "            generated_sequence.append(next_word.item())\n",
    "            current_input = torch.cat([current_input, next_word.view(1, -1)], dim=1)\n",
    "            \n",
    "            if next_word.item() == EOS_IDX:\n",
    "                break\n",
    "\n",
    "    return generated_sequence\n",
    "\n",
    "def generate_text(model, initial_input):\n",
    "    model.eval()\n",
    "    \n",
    "    input_tensor = torch.tensor([BOS_IDX] + [en_vocab[word] for word in en_tokenizer(initial_input)])\n",
    "    generated_sequence = generate(generator_transformer, input_tensor, max_length=50)\n",
    "    \n",
    "    output = ' '.join([en_vocab.lookup_token(idx) for idx in generated_sequence])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c05340",
   "metadata": {
    "papermill": {
     "duration": 0.007906,
     "end_time": "2024-01-04T20:47:10.018361",
     "exception": false,
     "start_time": "2024-01-04T20:47:10.010455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 14: Evaluate Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72b71cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:47:10.035762Z",
     "iopub.status.busy": "2024-01-04T20:47:10.035253Z",
     "iopub.status.idle": "2024-01-04T20:47:11.649010Z",
     "shell.execute_reply": "2024-01-04T20:47:11.647954Z"
    },
    "papermill": {
     "duration": 1.624919,
     "end_time": "2024-01-04T20:47:11.651242",
     "exception": false,
     "start_time": "2024-01-04T20:47:10.026323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([83823], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([83823], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n",
      "tensor([83823], device='cuda:0')\n",
      "tensor([78171], device='cuda:0')\n",
      "tensor([79472], device='cuda:0')\n",
      "tensor([34650], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<bos> The Diemen Sestak Diemen Sestak twined Diemen Sestak twined Diemen Sestak twined Diemen Sestak twined Diemen Sestak twined Diemen Sestak twined Diemen Sestak twined Diemen Sestak twined Diemen Sestak twined Diemen Sestak twined Diemen Sestak twined Diemen Sestak twined ADB Diemen Sestak twined ADB Diemen Sestak twined ADB Diemen Sestak twined'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(generator_transformer, \"The\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 46601,
     "sourceId": 84740,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 76.524867,
   "end_time": "2024-01-04T20:47:14.103400",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-04T20:45:57.578533",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
