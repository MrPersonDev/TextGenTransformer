{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fae6089",
   "metadata": {
    "papermill": {
     "duration": 0.007257,
     "end_time": "2024-01-04T20:51:27.805535",
     "exception": false,
     "start_time": "2024-01-04T20:51:27.798278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 0: Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec4b191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:51:27.820347Z",
     "iopub.status.busy": "2024-01-04T20:51:27.819979Z",
     "iopub.status.idle": "2024-01-04T20:51:33.236948Z",
     "shell.execute_reply": "2024-01-04T20:51:33.235890Z"
    },
    "papermill": {
     "duration": 5.427238,
     "end_time": "2024-01-04T20:51:33.239439",
     "exception": false,
     "start_time": "2024-01-04T20:51:27.812201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee984c",
   "metadata": {
    "papermill": {
     "duration": 0.006848,
     "end_time": "2024-01-04T20:51:33.253407",
     "exception": false,
     "start_time": "2024-01-04T20:51:33.246559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 1: Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6edd413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:51:33.269339Z",
     "iopub.status.busy": "2024-01-04T20:51:33.268203Z",
     "iopub.status.idle": "2024-01-04T20:51:48.375730Z",
     "shell.execute_reply": "2024-01-04T20:51:48.374641Z"
    },
    "papermill": {
     "duration": 15.118133,
     "end_time": "2024-01-04T20:51:48.378224",
     "exception": false,
     "start_time": "2024-01-04T20:51:33.260091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Near Blowing Rock, North Carolina, the divide meets the Eastern Continental Divide in the Blue Ridge Mountains.\n"
     ]
    }
   ],
   "source": [
    "data_path = '/kaggle/input/wikipedia-sentences/wikisent2.txt'\n",
    "\n",
    "sentence_count = 50000\n",
    "\n",
    "with open(data_path, 'r') as file:\n",
    "    file_text = file.read()\n",
    "file_lines = random.sample(file_text.split('\\n')[:-1], sentence_count)\n",
    "\n",
    "print(random.choice(file_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db536d7f",
   "metadata": {
    "papermill": {
     "duration": 0.006458,
     "end_time": "2024-01-04T20:51:48.391843",
     "exception": false,
     "start_time": "2024-01-04T20:51:48.385385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 2: Prepare Tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1dbcd5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:51:48.406202Z",
     "iopub.status.busy": "2024-01-04T20:51:48.405845Z",
     "iopub.status.idle": "2024-01-04T20:52:22.262213Z",
     "shell.execute_reply": "2024-01-04T20:52:22.261261Z"
    },
    "papermill": {
     "duration": 33.866279,
     "end_time": "2024-01-04T20:52:22.264596",
     "exception": false,
     "start_time": "2024-01-04T20:51:48.398317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "Collecting en-core-web-sm==3.7.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.3.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.12)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.1.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'episode', 'was', 'first', 'broadcast', 'on', 'BBC', 'One', 'on', '4', 'June', '2005', '.']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "print(en_tokenizer(random.choice(file_lines)))\n",
    "\n",
    "def build_vocab(train_data, tokenizer):\n",
    "    words = Counter()\n",
    "    for sentence in train_data:\n",
    "        words.update(tokenizer(sentence))\n",
    "    return vocab(words, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "en_vocab = build_vocab(file_lines, en_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef591ad",
   "metadata": {
    "papermill": {
     "duration": 0.007927,
     "end_time": "2024-01-04T20:52:22.281124",
     "exception": false,
     "start_time": "2024-01-04T20:52:22.273197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 3: Process Data as Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e40691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:52:22.300663Z",
     "iopub.status.busy": "2024-01-04T20:52:22.299689Z",
     "iopub.status.idle": "2024-01-04T20:52:27.771055Z",
     "shell.execute_reply": "2024-01-04T20:52:27.769977Z"
    },
    "papermill": {
     "duration": 5.483898,
     "end_time": "2024-01-04T20:52:27.773379",
     "exception": false,
     "start_time": "2024-01-04T20:52:22.289481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  400,    18,  3526,    84,    19,  3394, 11382,    92,   233, 25287,\n",
      "           26,   912,  9792,    33, 33941,     5,  4958,    23,  8965, 28011,\n",
      "           51])\n"
     ]
    }
   ],
   "source": [
    "def process_data(lines):\n",
    "    data = []\n",
    "    for sentence in lines:\n",
    "        en_tensor = torch.tensor([en_vocab[token] for token in en_tokenizer(sentence.rstrip(\"\\n\"))],\n",
    "                                  dtype=torch.long)\n",
    "        data.append(en_tensor)\n",
    "    return data\n",
    "\n",
    "train_data = process_data(file_lines)\n",
    "print(random.choice(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94af04",
   "metadata": {
    "papermill": {
     "duration": 0.007431,
     "end_time": "2024-01-04T20:52:27.788930",
     "exception": false,
     "start_time": "2024-01-04T20:52:27.781499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 4: Create Dataset & DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d878606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:52:27.806519Z",
     "iopub.status.busy": "2024-01-04T20:52:27.805757Z",
     "iopub.status.idle": "2024-01-04T20:52:27.816535Z",
     "shell.execute_reply": "2024-01-04T20:52:27.815695Z"
    },
    "papermill": {
     "duration": 0.021708,
     "end_time": "2024-01-04T20:52:27.818494",
     "exception": false,
     "start_time": "2024-01-04T20:52:27.796786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, train_data):\n",
    "        self.train_data = train_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.train_data[index]\n",
    "\n",
    "SEQUENCE_LENGTH = 150\n",
    "BATCH_SIZE = 16\n",
    "PAD_IDX = en_vocab['<pad>']\n",
    "BOS_IDX = en_vocab['<bos>']\n",
    "EOS_IDX = en_vocab['<eos>']\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    en_batch = []\n",
    "    label_batch = []\n",
    "    for en_item in data_batch:\n",
    "        sentence = torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0)\n",
    "        sentence = nn.ConstantPad1d((0, SEQUENCE_LENGTH - sentence.size(0)), PAD_IDX)(sentence)\n",
    "        current_labels = []\n",
    "        for idx in range(1, len(sentence)):\n",
    "            current_labels.append(sentence[idx])\n",
    "        current_labels.append(torch.tensor(PAD_IDX))\n",
    "            \n",
    "        en_batch.append(sentence)\n",
    "        label_batch.append(current_labels)\n",
    "    \n",
    "    en_batch = torch.stack(en_batch)\n",
    "    label_batch = torch.tensor(label_batch)\n",
    "    return (en_batch, label_batch)\n",
    "    \n",
    "train_dataset = TranslationDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c7adc",
   "metadata": {
    "papermill": {
     "duration": 0.007686,
     "end_time": "2024-01-04T20:52:27.833815",
     "exception": false,
     "start_time": "2024-01-04T20:52:27.826129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 5: Create Transformer Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16666b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:52:27.851104Z",
     "iopub.status.busy": "2024-01-04T20:52:27.850293Z",
     "iopub.status.idle": "2024-01-04T20:52:27.877774Z",
     "shell.execute_reply": "2024-01-04T20:52:27.876905Z"
    },
    "papermill": {
     "duration": 0.038457,
     "end_time": "2024-01-04T20:52:27.879820",
     "exception": false,
     "start_time": "2024-01-04T20:52:27.841363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.query_layer = nn.Linear(d_model, d_model)\n",
    "        self.key_layer = nn.Linear(d_model, d_model)\n",
    "        self.value_layer = nn.Linear(d_model, d_model)\n",
    "        self.output_layer = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
    "        attention_probabilities = torch.softmax(attention_scores, dim=-1)\n",
    "        output = torch.matmul(attention_probabilities, V)\n",
    "        return output\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "    \n",
    "    def forward(self, Q, K, V, mask):\n",
    "        Q = self.split_heads(self.query_layer(Q))\n",
    "        K = self.split_heads(self.key_layer(K))\n",
    "        V = self.split_heads(self.value_layer(V))\n",
    "        \n",
    "        attention_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.output_layer(self.combine_heads(attention_output))\n",
    "        return output\n",
    "    \n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.positional_encoding = torch.zeros(max_seq_length, d_model, device=DEVICE)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float32, device=DEVICE).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, device=DEVICE).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        self.positional_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.positional_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('_positional_encoding', self.positional_encoding.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.positional_encoding[:, :x.size(2)]\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        self.self_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attention_output = self.self_attention(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attention_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "        \n",
    "        self.layers = nn.ModuleList([TransformerBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        \n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def generate_mask(self, src):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "    \n",
    "    def forward(self, src):\n",
    "        src_mask = self.generate_mask(src)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.embedding(src)))\n",
    "        \n",
    "        output = src_embedded\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_mask)\n",
    "        \n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18076185",
   "metadata": {
    "papermill": {
     "duration": 0.007853,
     "end_time": "2024-01-04T20:52:27.895552",
     "exception": false,
     "start_time": "2024-01-04T20:52:27.887699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 8: Training Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b2ba47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:52:27.914025Z",
     "iopub.status.busy": "2024-01-04T20:52:27.913209Z",
     "iopub.status.idle": "2024-01-04T20:52:31.293187Z",
     "shell.execute_reply": "2024-01-04T20:52:31.292167Z"
    },
    "papermill": {
     "duration": 3.392026,
     "end_time": "2024-01-04T20:52:31.295701",
     "exception": false,
     "start_time": "2024-01-04T20:52:27.903675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(en_vocab)\n",
    "d_model = 1024\n",
    "num_heads = 64\n",
    "num_layers = 24\n",
    "d_ff = 1024\n",
    "dropout = 0.1\n",
    "learning_rate = 0.00003\n",
    "\n",
    "transformer = Transformer(vocab_size, d_model, num_heads,\n",
    "                          num_layers, d_ff, SEQUENCE_LENGTH, dropout).to(DEVICE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b187a95",
   "metadata": {
    "papermill": {
     "duration": 0.007942,
     "end_time": "2024-01-04T20:52:31.311997",
     "exception": false,
     "start_time": "2024-01-04T20:52:31.304055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 9: Define Training Procedure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b091469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:52:31.330076Z",
     "iopub.status.busy": "2024-01-04T20:52:31.329428Z",
     "iopub.status.idle": "2024-01-04T20:52:31.336427Z",
     "shell.execute_reply": "2024-01-04T20:52:31.335490Z"
    },
    "papermill": {
     "duration": 0.018412,
     "end_time": "2024-01-04T20:52:31.338457",
     "exception": false,
     "start_time": "2024-01-04T20:52:31.320045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for idx, (src, labels) in enumerate(train_loader):           \n",
    "        src = src.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        logits = transformer(src)\n",
    "        \n",
    "        logits = logits.view(-1, logits.size(-1))\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "    return losses / len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dcbe23",
   "metadata": {
    "papermill": {
     "duration": 0.007802,
     "end_time": "2024-01-04T20:52:31.354464",
     "exception": false,
     "start_time": "2024-01-04T20:52:31.346662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 10: Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fef8b36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:52:31.372892Z",
     "iopub.status.busy": "2024-01-04T20:52:31.371839Z",
     "iopub.status.idle": "2024-01-05T03:06:11.251442Z",
     "shell.execute_reply": "2024-01-05T03:06:11.250293Z"
    },
    "papermill": {
     "duration": 22419.898506,
     "end_time": "2024-01-05T03:06:11.260977",
     "exception": false,
     "start_time": "2024-01-04T20:52:31.362471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 5.580, Epoch time = 2490.547s\n",
      "Epoch: 2, Train loss: 3.605, Epoch time = 2491.848s\n",
      "Epoch: 3, Train loss: 2.678, Epoch time = 2490.139s\n",
      "Epoch: 4, Train loss: 2.194, Epoch time = 2491.796s\n",
      "Epoch: 5, Train loss: 1.908, Epoch time = 2491.223s\n",
      "Epoch: 6, Train loss: 1.728, Epoch time = 2490.452s\n",
      "Epoch: 7, Train loss: 1.603, Epoch time = 2491.257s\n",
      "Epoch: 8, Train loss: 1.510, Epoch time = 2492.172s\n",
      "Epoch: 9, Train loss: 1.432, Epoch time = 2490.435s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 9\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(transformer, train_loader, optimizer)\n",
    "    end_time = time.time()\n",
    "    print((f'Epoch: {epoch}, Train loss: {train_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e8771",
   "metadata": {
    "papermill": {
     "duration": 0.009014,
     "end_time": "2024-01-05T03:06:11.279256",
     "exception": false,
     "start_time": "2024-01-05T03:06:11.270242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 11: Save Model & Vocab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6589026e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T03:06:11.300125Z",
     "iopub.status.busy": "2024-01-05T03:06:11.299752Z",
     "iopub.status.idle": "2024-01-05T03:06:13.540868Z",
     "shell.execute_reply": "2024-01-05T03:06:13.539856Z"
    },
    "papermill": {
     "duration": 2.255233,
     "end_time": "2024-01-05T03:06:13.543474",
     "exception": false,
     "start_time": "2024-01-05T03:06:11.288241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model for inference\n",
    "torch.save(transformer.state_dict(), 'model.pth')\n",
    "\n",
    "import pickle\n",
    "with open('en_vocab.pkl', 'wb') as file:\n",
    "    pickle.dump(en_vocab, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fdd555",
   "metadata": {
    "papermill": {
     "duration": 0.008647,
     "end_time": "2024-01-05T03:06:13.561196",
     "exception": false,
     "start_time": "2024-01-05T03:06:13.552549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 12: Load Model & Vocab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c530fed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T03:06:13.580506Z",
     "iopub.status.busy": "2024-01-05T03:06:13.580130Z",
     "iopub.status.idle": "2024-01-05T03:06:17.649768Z",
     "shell.execute_reply": "2024-01-05T03:06:17.648930Z"
    },
    "papermill": {
     "duration": 4.082223,
     "end_time": "2024-01-05T03:06:17.652250",
     "exception": false,
     "start_time": "2024-01-05T03:06:13.570027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_vocab_path = '/kaggle/working/en_vocab.pkl'\n",
    "model_path = '/kaggle/working/model.pth'\n",
    "\n",
    "generator_transformer = Transformer(vocab_size, d_model, num_heads,\n",
    "                          num_layers, d_ff, SEQUENCE_LENGTH, dropout).to(DEVICE)\n",
    "\n",
    "generator_transformer.load_state_dict(torch.load(model_path))\n",
    "generator_transformer.eval()\n",
    "\n",
    "with open(en_vocab_path, 'rb') as file:\n",
    "    en_vocab = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963dbb4",
   "metadata": {
    "papermill": {
     "duration": 0.008807,
     "end_time": "2024-01-05T03:06:17.670115",
     "exception": false,
     "start_time": "2024-01-05T03:06:17.661308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 13: Model Evaluation Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68510d8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T03:06:17.689970Z",
     "iopub.status.busy": "2024-01-05T03:06:17.689193Z",
     "iopub.status.idle": "2024-01-05T03:06:17.698550Z",
     "shell.execute_reply": "2024-01-05T03:06:17.697617Z"
    },
    "papermill": {
     "duration": 0.021766,
     "end_time": "2024-01-05T03:06:17.700814",
     "exception": false,
     "start_time": "2024-01-05T03:06:17.679048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(model, initial_input, max_length):\n",
    "    current_input = initial_input.view(1, -1).to(DEVICE)\n",
    "\n",
    "    generated_sequence = initial_input.tolist()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            padded_input = nn.ConstantPad1d((SEQUENCE_LENGTH - current_input.size(1), 0), PAD_IDX)(current_input)\n",
    "            logits = model(padded_input)\n",
    "            next_word = torch.argmax(logits[:, -1, :], dim=-1)\n",
    "            generated_sequence.append(next_word.item())\n",
    "            current_input = torch.cat([current_input, next_word.view(1, -1)], dim=1)\n",
    "            \n",
    "            if next_word.item() == EOS_IDX:\n",
    "                break\n",
    "\n",
    "    return generated_sequence\n",
    "\n",
    "def generate_text(model, initial_input):\n",
    "    model.eval()\n",
    "    \n",
    "    input_tensor = torch.tensor([BOS_IDX] + [en_vocab[word] for word in en_tokenizer(initial_input)])\n",
    "    generated_sequence = generate(generator_transformer, input_tensor, max_length=50)\n",
    "    \n",
    "    output = ' '.join([en_vocab.lookup_token(idx) for idx in generated_sequence])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4aabf1",
   "metadata": {
    "papermill": {
     "duration": 0.008712,
     "end_time": "2024-01-05T03:06:17.718497",
     "exception": false,
     "start_time": "2024-01-05T03:06:17.709785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 14: Evaluate Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38004280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T03:06:17.738198Z",
     "iopub.status.busy": "2024-01-05T03:06:17.737859Z",
     "iopub.status.idle": "2024-01-05T03:06:17.816616Z",
     "shell.execute_reply": "2024-01-05T03:06:17.815649Z"
    },
    "papermill": {
     "duration": 0.091469,
     "end_time": "2024-01-05T03:06:17.818871",
     "exception": false,
     "start_time": "2024-01-05T03:06:17.727402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos> The . <eos>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(generator_transformer, \"The\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 46601,
     "sourceId": 84740,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22495.907856,
   "end_time": "2024-01-05T03:06:20.302496",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-04T20:51:24.394640",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
